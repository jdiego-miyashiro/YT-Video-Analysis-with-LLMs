Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:00:00---->00:01:00]:
yeah right okay I think we're ready to go well good morning everyone good morning you crazy cats I'm delighted to see so many of you here this morning um and want to learn a little bit more about the perfect couple so um we're a couple of months away from Valentine's but I just want to show you I'll illustrate to you a little bit how uh language models are in love with uh knowledge graphs and Indeed vice versa so so like the context here is to illustrate how by combining a large language model with the knowledge graph you basically have a have a beautiful uh marriage made in heaven as it were um before I kick it off quick word from our sponsors my name is Kristoff nce I'm part of the field engineering team at ne forj ne forj was established um effectively commercialized in 2010 we commercialized the graph database uh but in the meantime our software is has expanded quite substantially we now offer graph data analytics and visualization tools as well um and so

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:01:00---->00:02:00]:
that allows you basically to uh have an entire um uh graph technology ology platform for your connected data so um we've been re used uh by most of the large Enterprises in the world um and I think equally important for you guys here today is that everything I will illustrate and talk about today is open source right so everything you can use uh pretty much straight out of the box if you come and if you register and I'll explain that later on um we have about 250,000 registered developers that have um composed quite a lot of uh projects Etc we have about 5,000 questions answers on stack overflow so you're never going to get stuck and a ton of material to basically get going our software can be used so like anywhere that is on your own laptop and any of the big cloud providers Etc so um the topics we're going to cover here today quite a little quite a bit we're going to kick it off with um knowledge graphs and so I'm going to recap on the definition of a Knowledge Graph then I'm also going to illustrate how the key aspects of a Knowledge Graph integrate with the large language model and then

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:02:00---->00:03:00]:
we'll stress upon how you can use how you can can basically find implicit relationships in that Knowledge Graph in that factual information that you have and that's so like we'll come back a couple of times uh and then we'll go into the med and the potatoes of of the talk so we'll show how ultimately the integration of large language models with knowledge graphs can work as a front end uh user interface as it were and then also how we can do the heavy lifting uh in the back end so we'll explain that and as I said our software is entirely open source so towards the end if I time allows I will try and explain to you how you can get started on on your graph Journey um right so I would like to kick it off so like with the key theme of of the talk as it were um which I basically a quote I took over from from uh from Danny randich who who was part of the he's now part of wik dat and he started the knowledge graph project at at Google which kicked off the entire thing effectively and he's saying like in a world of infinite content knowledge becomes valuable and that's that's really the key thing right

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:03:00---->00:04:00]:
we already prior to chat GPT and the likes we already had substantial amount of content but now of course we have infinite content right that thing that that turns around 247 and so the question is how can we basically retain and ensure knowledge right so that is that is a key aspect here that we'll we'll try and stress um and then also so like my mission of effectively today is to make you effectively as excited as I am about these knowledge graphs and as I said try and show you how you can get started on your graph Journey later on we have a booth here uh 328 not in the middle of next to Microsoft effectively so if you have any questions please please please come and see us um and I've got a ton of material here that I will can share as well and and show you as well okay so first things first we're going to define a knowledge graph in its most basic concept and then see and then link it in with how that works with with a large language model so we're going to use sort like the most broadest academic definition that you can find effectively where we basically defining entities as um as objects so these could we we're

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:04:00---->00:05:00]:
going to build up a toy graph in a minute but these could be like people they could also be abstract Concepts then we have the explicit relationships between those entities and again we'll showcase that and then the key aspect ultimately around the knowledge graph and why and how they're so important around large language models is this concept of semantics okay and there's basically two key areas that we want to do here we want to use those large language models to ultimately create semantics that is to say create machine readable semantics uh for my knowledge graph and then another thing which I want to do is ultimately learn from my network structure of factual information I'm going to keep on repeating that one so learn from that Network structure through this amazing thing called graph machine learning graph data science Etc that allows me and there's a relatively recent development in in the AI machine learning space that allows me to learn from the connections that I have between my data points right and so we of course are very uh biased around it and you may think this guy from near for J looks all

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:05:00---->00:06:00]:
right but clearly the dude has been eating mushrooms but if you look at Google Deep Mind for instance right these guys are betting the farm effectively in terms of the technologies that they're using and if you're following a little bit what they've done with the protein folding Alpha fold Etc if you look down in what part of that architecture was a graph newal Network right so it's a very powerful structure and what you or powerful methods rather and what you want to do you want to deploy that on your knowledge graph to learn from that Network structure as it were so and that's going to come back later on where we're going to talk about how to integrate it with the language models and this called grounding okay so now we've defined so like the key definitions as it were the key Concepts let's have a look how we can build that one up and perhaps you can also have think about how this could potentially apply to your particular project that could be something in your Enterprise that could be fixtures in your tennis club as well right so in its core concept we start off with notes and in this simple example uh we have two person notes and a car note and what we're going to do we're going to Define some properties on these noes and this

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:06:00---->00:07:00]:
is also part of this semantics that we want to expand upon so let me explain so we have um basically in this case we have Dan we have um um um and so we got that date of birth we can expand on these Key properties and then what we have as well and this is where the large language models already come into play we have this thing called evolvo we are Swedish company as I said um but what we can add now we can add vectors to each node so we can have a vector store in this graph right what we have done here we have description and you see a vector the description of course initially was a blue car with yellow tires and red red seats or something along those lines right so I have a pi I have a string a chunk of text and now with these language models no surprise to you I can very efficiently very quickly convert that into a word embedding and then add that as a vector to my to my graph very powerful and I'll explain that later on but keep this concept in mind because I will we'll come back to it in a minute so now that we've got the notes we're going to Define obviously the relationships between those those

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:07:00---->00:08:00]:
explicit relationship he's in love with her fantastic she loves him back happy days they're living together um he's driving the car she of course paid for the whole thing and then one other thing that we can do we can add some more properties to those relationships which again talking about graph data science graph machine learning very powerful because I've got a descriptive um property here that he's been driving the car since January but I could also say a weighted relationship that he drives the car 5 days out of seven so for those of you familiar with graph Theory once I have a weighted graph I'm off to the races because a lot of things that I can do in terms of flow analysis Etc so happy days now we've defined a knowledge graph in its most basic form a most toy example as it were and now the fun really starts because one of the key aspects that you can do with a knowledge graph which you can't really do with any sort of like data structure as it were is that you can let it grow you can detect implicit relationships in your factual knowledge and so I'm going to contrast that later on with the with the language model so if we quick if we have a quick look at this toy example here we

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:08:00---->00:09:00]:
have a bunch of users um and they are visiting the web you know they're serving the web Etc well for me if people are using the same IP location so that is the same the same laptop the same phone yeah they're probably the same right so I can then immediately persist make that relationship explicit I can create a edge a relationship between those two users through the database and I can persist that that allows me then ultimately to to effectively extract subgraphs and do further analysis on this one and so in the context of large language models I can find implicit relationships between my factual knowledge there's no stochasticity involved here in this case right I know that they both are using an IP location this is what we're doing with entity resolution for instance so I can do a lot of these kind of things already through the query language and then on top of that and that's the whole machine learning graph machine learning graph data science aspect now there are very sophisticated methods now to find nonobvious implicit relationships in my data and then of course I can leverage

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:09:00---->00:10:00]:
this thing called the N graph data datase a native graph database like n4j to immediately persist that that implicit relationship and then we'll see that later on how we're going to feed that into the large language model so that's we basically why we're saying graphs grow organically you can gain ever better insights in your graph in your date which is not at your disposal if you leave it in a in a tbla format as it were great so now we've done that um if you want to know a little bit more in fact if you have like uh basically if you want to study these kind of things we just published or updated rather a book uh by my colleague Jesus and our chief scientist Jim Weber if you're interested in it come and see us at boot 328 and we'll show you how to get your free copy it's really a reference work now so um for those who want a little bit more comment see us right okay now as I said uh in the context of of of happy uh Happy Days and love how is sort of like a Knowledge Graph how can you integrate it with a language model and so conceptually there's sort like two major workflows you can think about these kind of things you can either see

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:10:00---->00:11:00]:
it on as sort like using it or deploying it as a user interface so as a front end I we'll see that in a minute what you can do with that or you can basically let it do the heavy lifting okay and so I'll explain to you the three major methods around that and there like but based on three pillars and I see a lot of you guys taking photos that's great thank you but you can also get the slides just come and see us and we'll send you the slides so we're we're totally open source um okay so as a front end um new forj has basically an interface called Neo Dash that is a dashboard that connects to you then your database again here open source you can deploy it at your own on your own projects um and so what we have now built into that dashboard is the ability for to convert natural language free text into Cipher Cipher is the query language of NE forj but also will become the standard uh when we move to a graph a graph query language in 24 um and so that allows you to as I said to use that ability that these large language models

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:11:00---->00:12:00]:
now have to write code this is very powerful right because now suddenly all of this technology becomes is becomes available to anyone in your organization or anyone that basically um wants to deploy ultimately a Knowledge Graph so hopefully this time works yeah so basically you now can see a little uh example of this one this would be your your dashboard so Neo Dash and what you have here now we will have a frame where you can add free text so show me a movie this one is linked to a movie database in the background it then will go into the open AI um engine convert it into a query which will see Now That Was Then basically converted that piece of natural language into a query gets run onto the database onto the movie database Returns the result and then you get results in this particular example it retains the context and information so you can basically continue to ask ask the questions around Etc so this is very powerful in addition we are also uh working now on basically fine-tuning a base model on a whole body of um of Cipher code and and that will then make

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:12:00---->00:13:00]:
it even more powerful but already now certainly with the GPT 4 engine uh we can we can do a lot so that's very powerful we'll see in a minute also how we're going to deploy that in dis tinal grounding okay now in terms of so like doing the heavy lifting um basically as you know uh these large language models um they've been developed um already since the Transformer area right so sorry the language model has been developed since the Transformer area we've done quite a lot of work um at new forj in using these Transformer models such as bio Etc to integrate with neop forj who we've got a lot a lot of expertise um and then of course since the explosion from November December with the um with the chat GPT lots of workflows were done lots of groups were established and so we managed to sort like find our little bit what works and what doesn't work and it was very encouraging to see that the paper was published in June um basically doing um or summarizing validating the approach that we did and so these guys have

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:13:00---->00:14:00]:
reviewed close to 5050 lit studies combining large language models with knowledge graphs and they've come up with basically a framework which I think is a very good way of looking at how you can use these language models so like to do the heavy lifting or rather the combination of both to do the heavy lifting so we are going to focus on the first two and let me quickly explain what they do so you can either have basically have a Knowledge Graph to enhance to augment your language model and we'll double click on that one a minute you can also have basically language models that augment your knowledge graph to do a lot of the work for you and again here we'll go into end we we'll explain that and then basically the Pape argues how you can have a Synergy and a continuous uh working between those two pillars as it were so that's basically what what we're going to focus on so first things first or first uh pillar knowledge graphs that enhance large language models what do we need to think about that so um as you know these language models they were trained on a large body of uh of of of

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:14:00---->00:15:00]:
of of of work effectively so I think the last the the Falcon model the largest falcon model was trained on uh 7even no 3.1 trillion of tokens um consuming something like 7 million GPU hours something like 4,000 gpus and and it's just they're just giving it away which is quite remarkable actually so consequently if you train it on a lot of stuff um certainly on Games of Thrones if you ask it something in Games of Thrones guess what is memorize it and we'll come will come with an answer and as you may have heard of this at the end of the day these language models they are manipulating strings right they're manipulating ultimately tokens there's no reason Etc so there's a bit of a problem there and you you can see where I'm going here um and so they're certainly not perfect but this at times at times they do push it they do push it and so I just want to like already warn you what's coming now maybe a little bit upsetting of some of you are there any just raise of hands any Germans or German football fans here no maybe they're a little bit shy anyway it's

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:15:00---->00:16:00]:
going to be a little bit stressing I'm sure there's lots of football uh English football fans so where were you on that you know faithful day effectively right so if you now look at back at at what happened and if you then ask if you then ask Chad GPT and that's why I'm saying there's no need for this if you reverse the question when did Germany beat England it sounds very credible it sounds very credible and it even says it there was a Munich Massacre right this will not happen in a graph because you have the direction of whom be who and of course the correct answer is that England be Germany and there was a Munich Miracle right so you have this thing which you may be familiar with well you all know is hallucination right and so that's a key drawback key problem with these large language models is that there is a lot of hallucination you can't really trust them and we'll see that in a minute as well and it's even a little bit more worrying that we did this in the same conversation and it still didn't grasp what it should be doing and what it should be answering so there's a bit of a problem here and so the key aspects here the key drawbacks

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:16:00---->00:17:00]:
as it were of basically these large language models is of course um garbage in garbage out but the problem is you don't even control the garbage in right you don't even know roughly what's going in it is some random stuff that's been trained on there is a cut off date as you know and then one of the key aspects here is that it sounds very credible we can't really verify this right so you have no certainty this thing who knows what it comes up with right and so this Paul chat was was a victim of that there was a lawyer that submitted some motions to court and he basically had the chat GPT come up with the arguments that he was presenting to the to the judge Etc and he had to pay a fine and and yeah anyway it was disgraced so basically the key drawbacks of these large language models they hallucinate and as you may have heard of this little comparison as well they make up random sentences from random people um they sound very credible like parrots do as well but what is the mean main difference here one is a cute little bird and the other one is is not right so now so that brings us to the the key aspect how can

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:17:00---->00:18:00]:
we solve this problem how can we use graphs to ultimately solve this problem and that is basically what there's so like three major ways of looking at solving this problem there is of course fine-tuning and here as well we can use knowledge graphs couple of things with fine-tuning you need a uh very well curated supervi labeled data set to do some supervised training so the literature says that you give or take need at least a th000 PA so these could be Q&A pairs this could be example result pairs Etc and then of course you need the manow and the brain power to do the you will Network extra training right so you can even feed a Knowledge Graph into that uh the team of Lovich at Stanford has done that and of course they they can do that you know but you need a lot of resources you need a lot of expertise to do that but it certainly Works equally said you do every time you want to add it with new information you need to retrain the whole banana again right so that's one way then you have the fuse shot learning that is a very powerful tool right so this is basically the prompting that you use to optimizing the prompting and then do this in

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:18:00---->00:19:00]:
context learning Etc there you can deploy the agents Lang chain Etc very powerful to ultimately limit the amount of nonsense that the language model can come up with and so you s like make it more specialized and then what we are going to focus on is this concept of grounding and so there a few talks today that will go into that as well it's very much respected or um see now in in in in in Industry as as so like the gold standard if you want to really reduce that sort of like element of hallucination and so what do we mean with grounding at the end of the day with grounding it comes down to basically forcing the language model large language model to use a specific data set that is created that is based on factual knowledge that you provide okay so it's limiting the amount of uh information limiting the amount and making it extremely specialized that's basically what you do couple of ways of doing that the one that we will be focusing on and certainly within the space of graphs is retrieval augmented generation so we're going to look at retrieval augmented generation uh of graphs and so let me quickly explain how

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:19:00---->00:20:00]:
this diagram works there effectively two ways of looking at it remember when I said that we can use the code writing abilities of the last language models well that's going to come what we do here we are using we are getting a question from our an internal customer external customer or whoever that question is in free text in natural language gets converted into a query that gets released run on my knowledge graph and then ultimately my knowledge graph is the factual information that I've curated that I've added to my graph database and there's a couple of things here that that um is to be stressed so I run this query and I'll come back then ultimately the results of that query as we just saw earlier that could be the results of who which movies did Jackel Nicholson played in or this could be very specific right this could be your knowledge graph on your domain uh area this could be your all of the technical documents uh that this your particular organization may have that you've build out in a Knowledge Graph and then you will return the query results together

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:20:00---->00:21:00]:
with the question to the language model so that it has the context and has the answer and then we're basically leveraging the language skills of the large language model so it's grammatical and language skills to produce an answer right and I can do this at scale the other thing that I had the benefit that I have remember what I said we want to find implicit relationships we want to learn metadata from our knowledge graph well that is something I can do effectively on a continuous basis I can find these implicit relationships add them to my knowledge graph and then ultimately feed it into ultimately my my cute little parrot and then it will come up with an answer right so the other workflow I can do remember that I said remember beautiful Volvo car it has a vector now right with description well every single note in that Knowledge Graph can have a vector that question I can have I have for my internal or external customer I can convert that into a vector I can do a vector search and then I can basically have all of the nodes that are related to that Vector

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:21:00---->00:22:00]:
returned and not only that I can can then surge the graph on that results so a little bit more involved happy to explain it to you into more detail but basically I can leverage the vector search capabilities with the context of the graph that it provides me so those are the two major workflows around grounding so what are the benefits here um of course I have accuracy right this is factual knowledge that I've created is in my graph database and I can continuously also check on that data there's are various tools of doing this ambiguation Etc so the other benefit is it's a flexible schema if tonight I get more customer information or I get new fixtures in my tennis I can just add it to the knowledge graph and and that is basically my source of Truth so I can almost use it in a real-time context right I can add more information real time as it were as opposed to saying fine tuning where I need to run the whole banana again very powerful then I can be very specific as I said I can feed it with domain specific knowledge this could be technical documents that

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:22:00---->00:23:00]:
I've basically analyzed made a Knowledge Graph out of it um Etc then the other thing is key aspect certainly for the financial services industry and other kind of industry I can explain where that answer comes from right so I have now I can trace back exactly the noes and the relationships that were traversed in my graph to know why it answered it in this way right the key facts are basically being returned there and then I can also restrict the um basically the access to that Knowledge Graph to that information to whoever asks it right so certain h information in my in my uh organization I don't want to share with everyone right and I do this through this thing called role based access control I can restrict which note can be seen by whoever which subgraph can be seen by whoever Etc so those are the like the key benefits of basically using uh this powerful uh data structure of a Knowledge Graph to do grounding for large language models so that's one pillar um then let's have a look at so like how can we now use these large language models to augment

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:23:00---->00:24:00]:
knowledge graphs and there basically we're leveraging two tried and tested techniques in NLP um Bas namely named entity recognition and knowledge compression and this is basically uh encoding and embedding so on terms of named entity recognition for those uh uh vers in in NLP tried and tested method the only drawback you have there is you need specialized libraries you need spacei and whatever you not it's also um need a little bit more expertise in that respect so you need um uh specialized teams and then getting that thing into production is proven to be a little bit um not straightforward all of the time right so that is now the world has changed the ease with which you can basically do named entity recognition using these large language models of course train on this large set of uh body of of work of text and then allowing you the key aspect two key aspects here allowing you to be extremely specific in the prompting to recognize which entities which relationships and then the other aspect

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:24:00---->00:25:00]:
is the output it generates for you you can basically find say in your prompting I need the results of my entities and relationships that you have extracted out of this text returned in a pandas data frame or a Json file or whatever format so very powerful way to automate the construction of your knowledge graph you can basically we're working with a client on 30 million PDFs that they're sitting on on converting that unstructured data text into a structured format and you can almost do it if you have enough compute power that is overnight so to speak right so that's so this is a very powerful way to sort like make stranded data text um more insightful very powerful and then the other exp example that we have is what we call or what maybe call Knowledge compression it's very simple text embedding and again here tried and test the technique in NLP but now so like the ubiquitous nature of these language models and the ease with which you can basically do an API call and convert any piece of text any string any description

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:25:00---->00:26:00]:
into to a vector and then write that Vector as a property to each note that's very powerful so as a quick example what we did here in this in this um in this example in this blog post this is something you can read is where we basically analyze all of the people that used to work at open Ai and then start at their own company and then what you can then do is basically say okay there's a bunch of articles that are related to whatever name was Danel or something like that soort a bunch of text media articles well I can basically link those articles and I can also summarize that text that article and I write it as a vector because what I can do now I can do a vector search on these articles I can find similarities I can then look up which article related to which note and I can find it further into the graph so I can get context around those articles right and again here nothing nothing new in terms of word embeddings and text embeddings but the scalability that you can do and the

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:26:00---->00:27:00]:
deployment in production is is very powerful and then so what we have done there's a tonging cheek here as I said we've always had the ability or may not said that but we always have the ability to write vectors to each Noe to write vectors in the near forj database we now have released indexing right so basically making Vector semantic search very very powerful and very quick that is to say very quick so we doing basically a sort of like at storage we we at store time we provide an index that makes at query time defining of similarities between vectors through either a cosine or ukan um method uh uh in real time as it were so that allows you then to as I showed you earlier with the grounding to do a search a similarity search a semantic search on those vectors that are properties to your Noe you get returned the nodes which are elements of course entities in your graph and then from that graph I can find the entire neighborhood right I can go one hop two hop 10 hops down in

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:27:00---->00:28:00]:
millisecond and I can get that wider context returned to me it's not just the top five red sweaters no if I do a top five red sweater search in a graph database with a vector search I get also I can also see which were the trousers that were bought to and if I go 10 hubs up I can see which demographic has been buying these red sweaters Etc so I can get really a very large body of context around that semantic surch so very powerful and then so basically as I said part of the mission of today was to make you as excited about uh knowledge graphs and language models as I am and so how can you get started so um NE forj has always been open source but we have now developed not now but we've over the years developed a lot of tools that allow you to get started in your journey and the quickest way that you can literally do in the next few minutes is to go through this thing called NE forj sandbox it's a cloud-based instance that we pay with hard cold cash uh and then give it to you and then you can basically um um either upload your own

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:28:00---->00:29:00]:
data or there's 12 pre-loaded data sets with like Twitter or fraud detection with some of them also a self-paced demo so that allows you to see how this graph Works how these thing works and then in addition on our website there's a ton of material we have a graph Academy we have you can do even do um uh certifications Etc all free of charge you even get a t-shirt Happy Days um so lots of material and then finally um this is a yeah I forgot to mention this basically we've also allowed now for um a very quick open AI or API calls to the likes of open Ai and why have you not but then finally we have a ton of blog posts that our dear esteemed colleague tomash has published around how to integrate with these language model so I can definitely uh encourage you to if you want to see what the usability and applications are of these language knowledge graphs he's done some amazing work in integrating it with basically creating uh chat G uh chat Bots um uh further knowledge graphs and a whole tons of things I mean basically the guy is a machine um so yeah lots of examples everything uh all

Video Extract : Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
[00:29:00---->End of Video]:
of the code is available on on the GitHub repository um and so you can get started on that so as I said part of my mission was was to show was to make you guys excited um I thank you very much for attending the talk today we have our booth at 328 myself and my colleagues will be there if you have any questions you want to have a copy of the book or any of the material links to the GitHub repositories Etc just come and find us thank you

